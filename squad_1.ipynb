{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidand/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 30 files: 100%|██████████| 30/30 [00:00<00:00, 23436.23it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.05627,  0.02858, -0.01721, ...,  0.02463, -0.0355 ,  0.0144 ],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from typing import List\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "from llama_index.core.base.embeddings.base import Embedding\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "import numpy as np\n",
    "model = BGEM3FlagModel(\"BAAI/bge-m3\", use_fp16=True)\n",
    "\n",
    "model.encode(\"Hello World\", batch_size=12, max_length=8192)[\"dense_vecs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser.text import SentenceSplitter\n",
    "text_splitter = SentenceSplitter(chunk_size=128, chunk_overlap=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87599/87599 [00:19<00:00, 4510.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 158985\n",
      "Original length: 87599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': '5733be284776f41900661182_0',\n",
       "  'chunk': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection.'},\n",
       " {'id': '5733be284776f41900661182_1',\n",
       "  'chunk': 'It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'},\n",
       " {'id': '5733be284776f4190066117f_0',\n",
       "  'chunk': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection.'},\n",
       " {'id': '5733be284776f4190066117f_1',\n",
       "  'chunk': 'It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'},\n",
       " {'id': '5733be284776f41900661180_0',\n",
       "  'chunk': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection.'},\n",
       " {'id': '5733be284776f41900661180_1',\n",
       "  'chunk': 'It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'},\n",
       " {'id': '5733be284776f41900661181_0',\n",
       "  'chunk': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection.'},\n",
       " {'id': '5733be284776f41900661181_1',\n",
       "  'chunk': 'It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'},\n",
       " {'id': '5733be284776f4190066117e_0',\n",
       "  'chunk': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection.'},\n",
       " {'id': '5733be284776f4190066117e_1',\n",
       "  'chunk': 'It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "# https://huggingface.co/datasets/hotpotqa/hotpot_qa?row=16\n",
    "# https://arxiv.org/pdf/1606.05250\n",
    "dataset = datasets.load_dataset(\"rajpurkar/squad\")\n",
    "\n",
    "# Split the context into chunks\n",
    "full_chunks = []\n",
    "for i in tqdm(range(len(dataset[\"train\"]))):\n",
    "    row = dataset[\"train\"][i]\n",
    "    chunks = text_splitter.split_text(row[\"context\"])\n",
    "    full_chunks.extend([\n",
    "        {\n",
    "            \"id\": f\"{row['id']}_{i}\",\n",
    "            \"chunk\": chunks[i],\n",
    "        }\n",
    "        for i in range(len(chunks))\n",
    "    ])\n",
    "\n",
    "print(\"Number of chunks:\", len(full_chunks))\n",
    "print(\"Original length:\", len(dataset[\"train\"]))\n",
    "full_chunks[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Embeddings: 100%|██████████| 13249/13249 [19:13<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.03357 , -0.001778, -0.0349  , ...,  0.03693 , -0.0222  ,\n",
       "        -0.000498],\n",
       "       [ 0.007965,  0.01884 , -0.0699  , ...,  0.03506 , -0.03018 ,\n",
       "        -0.02544 ],\n",
       "       [ 0.03357 , -0.001778, -0.0349  , ...,  0.03693 , -0.0222  ,\n",
       "        -0.000498],\n",
       "       ...,\n",
       "       [ 0.007965,  0.01884 , -0.0699  , ...,  0.03506 , -0.03018 ,\n",
       "        -0.02544 ],\n",
       "       [ 0.03357 , -0.001778, -0.0349  , ...,  0.03693 , -0.0222  ,\n",
       "        -0.000498],\n",
       "       [ 0.007965,  0.01884 , -0.0699  , ...,  0.03506 , -0.03018 ,\n",
       "        -0.02544 ]], dtype=float16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the embeddings\n",
    "embeddings = model.encode([chunk[\"chunk\"] for chunk in full_chunks], batch_size=12, max_length=8192)[\"dense_vecs\"]\n",
    "\n",
    "print(len(embeddings))\n",
    "embeddings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings to file as a checkpoint\n",
    "np.save(\"squad_embeddings.npy\", embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "class MyEmbeddingFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        embeddings = model.encode(input, batch_size=12, max_length=8192)[\"dense_vecs\"]\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159/159 [01:24<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from chromadb import Client\n",
    "\n",
    "chroma_client = Client()\n",
    "collection = chroma_client.create_collection(name=\"squad2\", embedding_function=MyEmbeddingFunction())\n",
    "batch_size = 1000\n",
    "for i in tqdm(range(0, len(embeddings), batch_size)):\n",
    "    end_idx = min(i + batch_size, len(embeddings))  # Ensure we don't go past the end\n",
    "    collection.add(\n",
    "        embeddings=embeddings[i:end_idx],\n",
    "        documents=[chunk[\"chunk\"] for chunk in full_chunks[i:end_idx]],\n",
    "        ids=[chunk[\"id\"] for chunk in full_chunks[i:end_idx]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['56dcddb066d3e219004dab4b_0',\n",
       "   '56dcddb066d3e219004dab47_0',\n",
       "   '56dcddb066d3e219004dab4a_0',\n",
       "   '56dcddb066d3e219004dab49_0',\n",
       "   '56dcddb066d3e219004dab48_0',\n",
       "   '570d7002b3d812140066d934_1',\n",
       "   '570d7002b3d812140066d931_1',\n",
       "   '570d7002b3d812140066d932_1',\n",
       "   '570d7002b3d812140066d935_1',\n",
       "   '570d7002b3d812140066d933_1']],\n",
       " 'embeddings': None,\n",
       " 'documents': [[\"The area north of the Congo River came under French sovereignty in 1880 as a result of Pierre de Brazza's treaty with Makoko of the Bateke. This Congo Colony became known first as French Congo, then as Middle Congo in 1903. In 1908, France organized French Equatorial Africa (AEF), comprising Middle Congo, Gabon, Chad, and Oubangui-Chari (the modern Central African Republic). The French designated Brazzaville as the federal capital. Economic development during the first 50 years of colonial rule in Congo centered on natural-resource extraction.\",\n",
       "   \"The area north of the Congo River came under French sovereignty in 1880 as a result of Pierre de Brazza's treaty with Makoko of the Bateke. This Congo Colony became known first as French Congo, then as Middle Congo in 1903. In 1908, France organized French Equatorial Africa (AEF), comprising Middle Congo, Gabon, Chad, and Oubangui-Chari (the modern Central African Republic). The French designated Brazzaville as the federal capital. Economic development during the first 50 years of colonial rule in Congo centered on natural-resource extraction.\",\n",
       "   \"The area north of the Congo River came under French sovereignty in 1880 as a result of Pierre de Brazza's treaty with Makoko of the Bateke. This Congo Colony became known first as French Congo, then as Middle Congo in 1903. In 1908, France organized French Equatorial Africa (AEF), comprising Middle Congo, Gabon, Chad, and Oubangui-Chari (the modern Central African Republic). The French designated Brazzaville as the federal capital. Economic development during the first 50 years of colonial rule in Congo centered on natural-resource extraction.\",\n",
       "   \"The area north of the Congo River came under French sovereignty in 1880 as a result of Pierre de Brazza's treaty with Makoko of the Bateke. This Congo Colony became known first as French Congo, then as Middle Congo in 1903. In 1908, France organized French Equatorial Africa (AEF), comprising Middle Congo, Gabon, Chad, and Oubangui-Chari (the modern Central African Republic). The French designated Brazzaville as the federal capital. Economic development during the first 50 years of colonial rule in Congo centered on natural-resource extraction.\",\n",
       "   \"The area north of the Congo River came under French sovereignty in 1880 as a result of Pierre de Brazza's treaty with Makoko of the Bateke. This Congo Colony became known first as French Congo, then as Middle Congo in 1903. In 1908, France organized French Equatorial Africa (AEF), comprising Middle Congo, Gabon, Chad, and Oubangui-Chari (the modern Central African Republic). The French designated Brazzaville as the federal capital. Economic development during the first 50 years of colonial rule in Congo centered on natural-resource extraction.\",\n",
       "   'Following the Siege of Paris, the capital fell on 28 January 1871 and then a revolutionary uprising called the Paris Commune seized power in the capital and held it for two months, until it was bloodily suppressed by the regular French army at the end of May 1871.',\n",
       "   'Following the Siege of Paris, the capital fell on 28 January 1871 and then a revolutionary uprising called the Paris Commune seized power in the capital and held it for two months, until it was bloodily suppressed by the regular French army at the end of May 1871.',\n",
       "   'Following the Siege of Paris, the capital fell on 28 January 1871 and then a revolutionary uprising called the Paris Commune seized power in the capital and held it for two months, until it was bloodily suppressed by the regular French army at the end of May 1871.',\n",
       "   'Following the Siege of Paris, the capital fell on 28 January 1871 and then a revolutionary uprising called the Paris Commune seized power in the capital and held it for two months, until it was bloodily suppressed by the regular French army at the end of May 1871.',\n",
       "   'Following the Siege of Paris, the capital fell on 28 January 1871 and then a revolutionary uprising called the Paris Commune seized power in the capital and held it for two months, until it was bloodily suppressed by the regular French army at the end of May 1871.']],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None, None, None, None, None, None, None, None, None]],\n",
       " 'distances': [[0.9237461686134338,\n",
       "   0.9237461686134338,\n",
       "   0.9237461686134338,\n",
       "   0.9237461686134338,\n",
       "   0.9237461686134338,\n",
       "   0.9350969791412354,\n",
       "   0.9350969791412354,\n",
       "   0.9350969791412354,\n",
       "   0.9350969791412354,\n",
       "   0.9350969791412354]],\n",
       " 'included': [<IncludeEnum.distances: 'distances'>,\n",
       "  <IncludeEnum.documents: 'documents'>,\n",
       "  <IncludeEnum.metadatas: 'metadatas'>]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search collection\n",
    "collection.query(\n",
    "    query_texts=[\"What is the capital of France?\"],\n",
    "    n_results=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Where is the headquarters of the Congregation of the Holy Cross?'\n",
      "{'data': None,\n",
      " 'distances': [[0.8609922528266907,\n",
      "                0.8609922528266907,\n",
      "                0.8609922528266907,\n",
      "                0.8609922528266907,\n",
      "                0.8609922528266907,\n",
      "                0.9223301410675049,\n",
      "                0.9223301410675049,\n",
      "                0.9223301410675049,\n",
      "                0.9223301410675049,\n",
      "                0.9223301410675049]],\n",
      " 'documents': [['The university is the major seat of the Congregation of Holy '\n",
      "                'Cross (albeit not its official headquarters, which are in '\n",
      "                'Rome). Its main seminary, Moreau Seminary, is located on the '\n",
      "                'campus across St. Joseph lake from the Main Building. Old '\n",
      "                'College, the oldest building on campus and located near the '\n",
      "                'shore of St. Mary lake, houses undergraduate seminarians. '\n",
      "                'Retired priests and brothers reside in Fatima House (a former '\n",
      "                'retreat center), Holy Cross House, as well as Columba Hall '\n",
      "                'near the Grotto.',\n",
      "                'The university is the major seat of the Congregation of Holy '\n",
      "                'Cross (albeit not its official headquarters, which are in '\n",
      "                'Rome). Its main seminary, Moreau Seminary, is located on the '\n",
      "                'campus across St. Joseph lake from the Main Building. Old '\n",
      "                'College, the oldest building on campus and located near the '\n",
      "                'shore of St. Mary lake, houses undergraduate seminarians. '\n",
      "                'Retired priests and brothers reside in Fatima House (a former '\n",
      "                'retreat center), Holy Cross House, as well as Columba Hall '\n",
      "                'near the Grotto.',\n",
      "                'The university is the major seat of the Congregation of Holy '\n",
      "                'Cross (albeit not its official headquarters, which are in '\n",
      "                'Rome). Its main seminary, Moreau Seminary, is located on the '\n",
      "                'campus across St. Joseph lake from the Main Building. Old '\n",
      "                'College, the oldest building on campus and located near the '\n",
      "                'shore of St. Mary lake, houses undergraduate seminarians. '\n",
      "                'Retired priests and brothers reside in Fatima House (a former '\n",
      "                'retreat center), Holy Cross House, as well as Columba Hall '\n",
      "                'near the Grotto.',\n",
      "                'The university is the major seat of the Congregation of Holy '\n",
      "                'Cross (albeit not its official headquarters, which are in '\n",
      "                'Rome). Its main seminary, Moreau Seminary, is located on the '\n",
      "                'campus across St. Joseph lake from the Main Building. Old '\n",
      "                'College, the oldest building on campus and located near the '\n",
      "                'shore of St. Mary lake, houses undergraduate seminarians. '\n",
      "                'Retired priests and brothers reside in Fatima House (a former '\n",
      "                'retreat center), Holy Cross House, as well as Columba Hall '\n",
      "                'near the Grotto.',\n",
      "                'The university is the major seat of the Congregation of Holy '\n",
      "                'Cross (albeit not its official headquarters, which are in '\n",
      "                'Rome). Its main seminary, Moreau Seminary, is located on the '\n",
      "                'campus across St. Joseph lake from the Main Building. Old '\n",
      "                'College, the oldest building on campus and located near the '\n",
      "                'shore of St. Mary lake, houses undergraduate seminarians. '\n",
      "                'Retired priests and brothers reside in Fatima House (a former '\n",
      "                'retreat center), Holy Cross House, as well as Columba Hall '\n",
      "                'near the Grotto.',\n",
      "                'Boston has been a noted religious center from its earliest '\n",
      "                'days. The Roman Catholic Archdiocese of Boston serves nearly '\n",
      "                '300 parishes and is based in the Cathedral of the Holy Cross '\n",
      "                '(1875) in the South End, while the Episcopal Diocese of '\n",
      "                'Massachusetts, with the Cathedral Church of St. Paul (1819) '\n",
      "                'as its episcopal seat, serves just under 200 congregations. '\n",
      "                'Unitarian Universalism has its headquarters on Beacon Hill. '\n",
      "                'The Christian Scientists are headquartered in Back Bay at the '\n",
      "                'Mother Church (1894).',\n",
      "                'Boston has been a noted religious center from its earliest '\n",
      "                'days. The Roman Catholic Archdiocese of Boston serves nearly '\n",
      "                '300 parishes and is based in the Cathedral of the Holy Cross '\n",
      "                '(1875) in the South End, while the Episcopal Diocese of '\n",
      "                'Massachusetts, with the Cathedral Church of St. Paul (1819) '\n",
      "                'as its episcopal seat, serves just under 200 congregations. '\n",
      "                'Unitarian Universalism has its headquarters on Beacon Hill. '\n",
      "                'The Christian Scientists are headquartered in Back Bay at the '\n",
      "                'Mother Church (1894).',\n",
      "                'Boston has been a noted religious center from its earliest '\n",
      "                'days. The Roman Catholic Archdiocese of Boston serves nearly '\n",
      "                '300 parishes and is based in the Cathedral of the Holy Cross '\n",
      "                '(1875) in the South End, while the Episcopal Diocese of '\n",
      "                'Massachusetts, with the Cathedral Church of St. Paul (1819) '\n",
      "                'as its episcopal seat, serves just under 200 congregations. '\n",
      "                'Unitarian Universalism has its headquarters on Beacon Hill. '\n",
      "                'The Christian Scientists are headquartered in Back Bay at the '\n",
      "                'Mother Church (1894).',\n",
      "                'Boston has been a noted religious center from its earliest '\n",
      "                'days. The Roman Catholic Archdiocese of Boston serves nearly '\n",
      "                '300 parishes and is based in the Cathedral of the Holy Cross '\n",
      "                '(1875) in the South End, while the Episcopal Diocese of '\n",
      "                'Massachusetts, with the Cathedral Church of St. Paul (1819) '\n",
      "                'as its episcopal seat, serves just under 200 congregations. '\n",
      "                'Unitarian Universalism has its headquarters on Beacon Hill. '\n",
      "                'The Christian Scientists are headquartered in Back Bay at the '\n",
      "                'Mother Church (1894).',\n",
      "                'Boston has been a noted religious center from its earliest '\n",
      "                'days. The Roman Catholic Archdiocese of Boston serves nearly '\n",
      "                '300 parishes and is based in the Cathedral of the Holy Cross '\n",
      "                '(1875) in the South End, while the Episcopal Diocese of '\n",
      "                'Massachusetts, with the Cathedral Church of St. Paul (1819) '\n",
      "                'as its episcopal seat, serves just under 200 congregations. '\n",
      "                'Unitarian Universalism has its headquarters on Beacon Hill. '\n",
      "                'The Christian Scientists are headquartered in Back Bay at the '\n",
      "                'Mother Church (1894).']],\n",
      " 'embeddings': None,\n",
      " 'ids': [['5733bed24776f4190066118b_0',\n",
      "          '5733bed24776f4190066118c_0',\n",
      "          '5733bed24776f41900661188_0',\n",
      "          '5733bed24776f41900661189_0',\n",
      "          '5733bed24776f4190066118a_0',\n",
      "          '56e15bbfe3433e1400422e00_0',\n",
      "          '56e15bbfe3433e1400422dfe_0',\n",
      "          '56e15bbfe3433e1400422dfc_0',\n",
      "          '56e15bbfe3433e1400422dff_0',\n",
      "          '56e15bbfe3433e1400422dfd_0']],\n",
      " 'included': [<IncludeEnum.distances: 'distances'>,\n",
      "              <IncludeEnum.documents: 'documents'>,\n",
      "              <IncludeEnum.metadatas: 'metadatas'>],\n",
      " 'metadatas': [[None, None, None, None, None, None, None, None, None, None]],\n",
      " 'uris': None}\n",
      "'5733bed24776f41900661188'\n",
      "['5733bed24776f4190066118b',\n",
      " '5733bed24776f4190066118c',\n",
      " '5733bed24776f41900661188',\n",
      " '5733bed24776f41900661189',\n",
      " '5733bed24776f4190066118a',\n",
      " '56e15bbfe3433e1400422e00',\n",
      " '56e15bbfe3433e1400422dfe',\n",
      " '56e15bbfe3433e1400422dfc',\n",
      " '56e15bbfe3433e1400422dff',\n",
      " '56e15bbfe3433e1400422dfd']\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision for one example\n",
    "# By checking document ids\n",
    "precision = 0\n",
    "i = 10\n",
    "row = dataset[\"train\"][i]\n",
    "query = row[\"question\"]\n",
    "results = collection.query(query_texts=[query], n_results=10)\n",
    "ids = results[\"ids\"][0]\n",
    "ground_truth = row[\"id\"]\n",
    "original_ids = [id.split(\"_\")[0] for id in ids]\n",
    "precision = sum([1 for id in original_ids if id == ground_truth]) / len(original_ids)\n",
    "pprint(query)\n",
    "pprint(results)\n",
    "pprint(ground_truth)\n",
    "pprint(original_ids)\n",
    "pprint(precision)\n",
    "# This doesn't work because there are duplicate contexts in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In what year did the team lead by Knute Rockne win the Rose Bowl?'\n",
      "'answer: 1925'\n",
      "{'data': None,\n",
      " 'distances': [[1.2871770858764648,\n",
      "                1.2871770858764648,\n",
      "                1.2871770858764648,\n",
      "                1.2871770858764648,\n",
      "                1.2871770858764648,\n",
      "                1.2901089191436768,\n",
      "                1.2901089191436768,\n",
      "                1.2901089191436768,\n",
      "                1.2901089191436768,\n",
      "                1.2923610210418701]],\n",
      " 'documents': [['By the early 1980s, Queen were one of the biggest stadium '\n",
      "                \"rock bands in the world. Their performance at 1985's Live Aid \"\n",
      "                'is ranked among the greatest in rock history by various music '\n",
      "                'publications, with a 2005 industry poll ranking it the best. '\n",
      "                'In 1991, Mercury died of bronchopneumonia, a complication of '\n",
      "                'AIDS, and Deacon retired in 1997. Since then, May and Taylor '\n",
      "                'have occasionally performed together, including with Paul '\n",
      "                'Rodgers (2004–09) and with Adam Lambert (since 2011).',\n",
      "                'By the early 1980s, Queen were one of the biggest stadium '\n",
      "                \"rock bands in the world. Their performance at 1985's Live Aid \"\n",
      "                'is ranked among the greatest in rock history by various music '\n",
      "                'publications, with a 2005 industry poll ranking it the best. '\n",
      "                'In 1991, Mercury died of bronchopneumonia, a complication of '\n",
      "                'AIDS, and Deacon retired in 1997. Since then, May and Taylor '\n",
      "                'have occasionally performed together, including with Paul '\n",
      "                'Rodgers (2004–09) and with Adam Lambert (since 2011).',\n",
      "                'By the early 1980s, Queen were one of the biggest stadium '\n",
      "                \"rock bands in the world. Their performance at 1985's Live Aid \"\n",
      "                'is ranked among the greatest in rock history by various music '\n",
      "                'publications, with a 2005 industry poll ranking it the best. '\n",
      "                'In 1991, Mercury died of bronchopneumonia, a complication of '\n",
      "                'AIDS, and Deacon retired in 1997. Since then, May and Taylor '\n",
      "                'have occasionally performed together, including with Paul '\n",
      "                'Rodgers (2004–09) and with Adam Lambert (since 2011).',\n",
      "                'By the early 1980s, Queen were one of the biggest stadium '\n",
      "                \"rock bands in the world. Their performance at 1985's Live Aid \"\n",
      "                'is ranked among the greatest in rock history by various music '\n",
      "                'publications, with a 2005 industry poll ranking it the best. '\n",
      "                'In 1991, Mercury died of bronchopneumonia, a complication of '\n",
      "                'AIDS, and Deacon retired in 1997. Since then, May and Taylor '\n",
      "                'have occasionally performed together, including with Paul '\n",
      "                'Rodgers (2004–09) and with Adam Lambert (since 2011).',\n",
      "                'By the early 1980s, Queen were one of the biggest stadium '\n",
      "                \"rock bands in the world. Their performance at 1985's Live Aid \"\n",
      "                'is ranked among the greatest in rock history by various music '\n",
      "                'publications, with a 2005 industry poll ranking it the best. '\n",
      "                'In 1991, Mercury died of bronchopneumonia, a complication of '\n",
      "                'AIDS, and Deacon retired in 1997. Since then, May and Taylor '\n",
      "                'have occasionally performed together, including with Paul '\n",
      "                'Rodgers (2004–09) and with Adam Lambert (since 2011).',\n",
      "                'It has been hailed as launching the MTV age. Acclaimed for '\n",
      "                \"their stadium rock, in 2005 an industry poll ranked Queen's \"\n",
      "                'performance at Live Aid in 1985 as the best live act in '\n",
      "                'history. In 2007, they were also voted the greatest British '\n",
      "                'band in history by BBC Radio 2 listeners.',\n",
      "                'It has been hailed as launching the MTV age. Acclaimed for '\n",
      "                \"their stadium rock, in 2005 an industry poll ranked Queen's \"\n",
      "                'performance at Live Aid in 1985 as the best live act in '\n",
      "                'history. In 2007, they were also voted the greatest British '\n",
      "                'band in history by BBC Radio 2 listeners.',\n",
      "                'It has been hailed as launching the MTV age. Acclaimed for '\n",
      "                \"their stadium rock, in 2005 an industry poll ranked Queen's \"\n",
      "                'performance at Live Aid in 1985 as the best live act in '\n",
      "                'history. In 2007, they were also voted the greatest British '\n",
      "                'band in history by BBC Radio 2 listeners.',\n",
      "                'It has been hailed as launching the MTV age. Acclaimed for '\n",
      "                \"their stadium rock, in 2005 an industry poll ranked Queen's \"\n",
      "                'performance at Live Aid in 1985 as the best live act in '\n",
      "                'history. In 2007, they were also voted the greatest British '\n",
      "                'band in history by BBC Radio 2 listeners.',\n",
      "                'In October of the same year, Queen performed for more than '\n",
      "                '150,000 fans on 9 October at Monterrey (Estadio '\n",
      "                'Universitario) and 17 and 18 at Puebla (Estadio Zaragoza), '\n",
      "                'Mexico. On 24 and 25 November, Queen played two sell out '\n",
      "                'nights at the Montreal Forum, Quebec, Canada. One of '\n",
      "                \"Mercury's most notable performances of The Game's final \"\n",
      "                'track, \"Save Me\", took place in Montreal, and the concert is '\n",
      "                'recorded in the live album, Queen Rock Montreal.']],\n",
      " 'embeddings': None,\n",
      " 'ids': [['57265492f1498d1400e8dc32_2',\n",
      "          '57265492f1498d1400e8dc36_2',\n",
      "          '57265492f1498d1400e8dc34_2',\n",
      "          '57265492f1498d1400e8dc35_2',\n",
      "          '57265492f1498d1400e8dc33_2',\n",
      "          '5726d732708984140094d30a_1',\n",
      "          '5726d732708984140094d308_1',\n",
      "          '5726d732708984140094d307_1',\n",
      "          '5726d732708984140094d309_1',\n",
      "          '57269470dd62a815002e8a35_1']],\n",
      " 'included': [<IncludeEnum.distances: 'distances'>,\n",
      "              <IncludeEnum.documents: 'documents'>,\n",
      "              <IncludeEnum.metadatas: 'metadatas'>],\n",
      " 'metadatas': [[None, None, None, None, None, None, None, None, None, None]],\n",
      " 'uris': None}\n",
      "'precision: 0.0'\n"
     ]
    }
   ],
   "source": [
    "# Let's check if the substring is in the document\n",
    "i = 100\n",
    "row = dataset[\"train\"][i]\n",
    "query = row[\"question\"]\n",
    "answer = row[\"answers\"][\"text\"][0]\n",
    "results = collection.query(query_texts=[query], n_results=10)\n",
    "precision = sum([1 for result in results[\"documents\"][0] if answer in result]) / len(results[\"documents\"][0])\n",
    "pprint(query)\n",
    "pprint(\"answer: \" + answer)\n",
    "pprint(results)\n",
    "pprint(\"precision: \" + str(precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 12769/87599 [19:18<1:53:09, 11.02it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m query \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m answer \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswers\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m precision \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m answer \u001b[38;5;129;01min\u001b[39;00m result]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocuments\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      8\u001b[0m precisions\u001b[38;5;241m.\u001b[39mappend(precision)\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/chromadb/api/models/Collection.py:210\u001b[0m, in \u001b[0;36mCollection.query\u001b[0;34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    169\u001b[0m     query_embeddings: Optional[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m     ],\n\u001b[1;32m    186\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m QueryResult:\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the n_results nearest neighbor embeddings for provided query_embeddings or query_texts.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     query_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_and_prepare_query_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_uris\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_uris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     query_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_query(\n\u001b[1;32m    222\u001b[0m         collection_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    223\u001b[0m         query_embeddings\u001b[38;5;241m=\u001b[39mquery_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    229\u001b[0m         database\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatabase,\n\u001b[1;32m    230\u001b[0m     )\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_query_response(\n\u001b[1;32m    233\u001b[0m         response\u001b[38;5;241m=\u001b[39mquery_results, include\u001b[38;5;241m=\u001b[39mquery_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    234\u001b[0m     )\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/chromadb/api/models/CollectionCommon.py:90\u001b[0m, in \u001b[0;36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     92\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/chromadb/api/models/CollectionCommon.py:301\u001b[0m, in \u001b[0;36mCollectionCommon._validate_and_prepare_query_request\u001b[0;34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m query_records[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m     validate_record_set_for_embedding(record_set\u001b[38;5;241m=\u001b[39mquery_records)\n\u001b[0;32m--> 301\u001b[0m     request_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     request_embeddings \u001b[38;5;241m=\u001b[39m query_records[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/chromadb/api/models/CollectionCommon.py:526\u001b[0m, in \u001b[0;36mCollectionCommon._embed_record_set\u001b[0;34m(self, record_set, embeddable_fields)\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed(\n\u001b[1;32m    523\u001b[0m                 \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_loader(uris\u001b[38;5;241m=\u001b[39mcast(URIs, record_set[field]))  \u001b[38;5;66;03m# type: ignore[literal-required]\u001b[39;00m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 526\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[literal-required]\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecord does not contain any non-None fields that can be embedded.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddable Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddable_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecord Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    531\u001b[0m )\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/chromadb/api/models/CollectionCommon.py:539\u001b[0m, in \u001b[0;36mCollectionCommon._embed\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    536\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must provide an embedding function to compute embeddings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.trychroma.com/guides/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    538\u001b[0m     )\n\u001b[0;32m--> 539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/chromadb/api/types.py:460\u001b[0m, in \u001b[0;36mEmbeddingFunction.__init_subclass__.<locals>.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m: EmbeddingFunction[D], \u001b[38;5;28minput\u001b[39m: D) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Embeddings:\n\u001b[0;32m--> 460\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_embeddings(cast(Embeddings, normalize_embeddings(result)))\n",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m, in \u001b[0;36mMyEmbeddingFunction.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Documents) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Embeddings:\n\u001b[0;32m----> 4\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8192\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense_vecs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/FlagEmbedding/inference/embedder/encoder_only/m3.py:207\u001b[0m, in \u001b[0;36mM3Embedder.encode\u001b[0;34m(self, queries, batch_size, max_length, return_dense, return_sparse, return_colbert_vecs, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_sparse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: return_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_sparse\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_colbert_vecs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: return_colbert_vecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_colbert_vecs\n\u001b[0;32m--> 207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dense\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dense\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_colbert_vecs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_colbert_vecs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/FlagEmbedding/abc/inference/AbsEmbedder.py:237\u001b[0m, in \u001b[0;36mAbsEmbedder.encode\u001b[0;34m(self, sentences, batch_size, max_length, convert_to_numpy, instruction, instruction_format, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m         sentences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_detailed_instruct(instruction_format, instruction, sentence) \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m    234\u001b[0m                      sentences]\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(sentences, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_devices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_single_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_devices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_multi_process_pool(AbsEmbedder\u001b[38;5;241m.\u001b[39m_encode_multi_process_worker)\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/FlagEmbedding/inference/embedder/encoder_only/m3.py:238\u001b[0m, in \u001b[0;36mM3Embedder.encode_single_device\u001b[0;34m(self, sentences, batch_size, max_length, return_dense, return_sparse, return_colbert_vecs, device, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_fp16 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_fp16: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mhalf()\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    241\u001b[0m input_was_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 900 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/hello-retrieval-eval/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1328\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1327\u001b[0m         device,\n\u001b[0;32m-> 1328\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1329\u001b[0m         non_blocking,\n\u001b[1;32m   1330\u001b[0m     )\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "precisions = [] \n",
    "for i in tqdm(range(len(dataset[\"train\"]))):\n",
    "    row = dataset[\"train\"][i]\n",
    "    query = row[\"question\"]\n",
    "    answer = row[\"answers\"][\"text\"][0]\n",
    "    results = collection.query(query_texts=[query], n_results=10)\n",
    "    precision = sum([1 for result in results[\"documents\"][0] if answer in result]) / len(results[\"documents\"][0])\n",
    "    precisions.append(precision)\n",
    "\n",
    "np.mean(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2738/2738 [06:36<00:00,  6.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# Super slow let's try a few things:\n",
    "# 1. query in batches\n",
    "# 2. Update the precision count via a set\n",
    "# Batch process queries\n",
    "batch_size = 32  # Adjust based on your memory constraints\n",
    "precisions = []\n",
    "\n",
    "for i in tqdm(range(0, len(dataset[\"train\"]), batch_size)):\n",
    "    # Get batch of questions and answers\n",
    "    batch_slice = slice(i, min(i + batch_size, len(dataset[\"train\"])))\n",
    "    batch_rows = dataset[\"train\"][batch_slice]\n",
    "    batch_queries = batch_rows[\"question\"]\n",
    "    batch_answers = [ans[\"text\"][0] for ans in batch_rows[\"answers\"]]\n",
    "    \n",
    "    # Batch query ChromaDB\n",
    "    results = collection.query(\n",
    "        query_texts=batch_queries,\n",
    "        n_results=10\n",
    "    )\n",
    "    \n",
    "    # Calculate precision for each query in batch\n",
    "    for query_idx, (answer, documents) in enumerate(zip(batch_answers, results[\"documents\"])):\n",
    "        # Convert to set for faster lookup\n",
    "        answer_matches = sum(1 for doc in documents if answer in doc)\n",
    "        precision = answer_matches / len(documents)\n",
    "        precisions.append(precision)\n",
    "\n",
    "mean_precision = np.mean(precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.23560885398235137)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_precision\n",
    "# Answer they got was 0.1246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 331/331 [00:44<00:00,  7.43it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32  # Adjust based on your memory constraints\n",
    "precisions = []\n",
    "\n",
    "split = \"validation\"\n",
    "\n",
    "for i in tqdm(range(0, len(dataset[split]), batch_size)):\n",
    "    # Get batch of questions and answers\n",
    "    batch_slice = slice(i, min(i + batch_size, len(dataset[split])))\n",
    "    batch_rows = dataset[split][batch_slice]\n",
    "    batch_queries = batch_rows[\"question\"]\n",
    "    batch_answers = [ans[\"text\"][0] for ans in batch_rows[\"answers\"]]\n",
    "    \n",
    "    # Batch query ChromaDB\n",
    "    results = collection.query(\n",
    "        query_texts=batch_queries,\n",
    "        n_results=10\n",
    "    )\n",
    "    \n",
    "    # Calculate precision for each query in batch\n",
    "    for query_idx, (answer, documents) in enumerate(zip(batch_answers, results[\"documents\"])):\n",
    "        # Convert to set for faster lookup\n",
    "        answer_matches = sum(1 for doc in documents if answer in doc)\n",
    "        precision = answer_matches / len(documents)\n",
    "        precisions.append(precision)\n",
    "\n",
    "mean_precision = np.mean(precisions)\n",
    "mean_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.026887417218543045)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3068/3068 [07:11<00:00,  7.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.2131344925587507)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "batch_size = 32  # Adjust based on your memory constraints\n",
    "precisions = []\n",
    "\n",
    "joined_dataset = concatenate_datasets([dataset[\"train\"], dataset[\"validation\"]])\n",
    "\n",
    "for i in tqdm(range(0, len(joined_dataset), batch_size)):\n",
    "    # Get batch of questions and answers\n",
    "    batch_slice = slice(i, min(i + batch_size, len(joined_dataset)))\n",
    "    batch_rows = joined_dataset[batch_slice]\n",
    "    batch_queries = batch_rows[\"question\"]\n",
    "    batch_answers = [ans[\"text\"][0] for ans in batch_rows[\"answers\"]]\n",
    "    \n",
    "    # Batch query ChromaDB\n",
    "    results = collection.query(\n",
    "        query_texts=batch_queries,\n",
    "        n_results=10\n",
    "    )\n",
    "    \n",
    "    # Calculate precision for each query in batch\n",
    "    for query_idx, (answer, documents) in enumerate(zip(batch_answers, results[\"documents\"])):\n",
    "        # Convert to set for faster lookup\n",
    "        answer_matches = sum(1 for doc in documents if answer in doc)\n",
    "        precision = answer_matches / len(documents)\n",
    "        precisions.append(precision)\n",
    "\n",
    "mean_precision = np.mean(precisions)\n",
    "mean_precision\n",
    "# They got 0.1246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2738 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m batch_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(i, \u001b[38;5;28mmin\u001b[39m(i \u001b[38;5;241m+\u001b[39m batch_size, \u001b[38;5;28mlen\u001b[39m(joined_dataset)))\n\u001b[1;32m     11\u001b[0m batch_rows \u001b[38;5;241m=\u001b[39m joined_dataset[batch_slice]\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbatch_rows\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     13\u001b[0m batch_queries \u001b[38;5;241m=\u001b[39m batch_rows[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     14\u001b[0m batch_ground_truth_ids \u001b[38;5;241m=\u001b[39m [row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m batch_rows]\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Let's try whether the document_id matches\n",
    "\n",
    "from datasets import concatenate_datasets\n",
    "batch_size = 32  # Adjust based on your memory constraints\n",
    "precisions = []\n",
    "\n",
    "joined_dataset = dataset[\"train\"]\n",
    "for i in tqdm(range(0, len(joined_dataset), batch_size)):\n",
    "    # Get batch of questions and answers\n",
    "    batch_slice = slice(i, min(i + batch_size, len(joined_dataset)))\n",
    "    batch_rows = joined_dataset[batch_slice]\n",
    "    print(batch_rows[0])\n",
    "    batch_queries = batch_rows[\"question\"]\n",
    "    batch_ground_truth_ids = [row[\"id\"] for row in batch_rows]\n",
    "    \n",
    "    # Batch query ChromaDB\n",
    "    results = collection.query(\n",
    "        query_texts=batch_queries,\n",
    "        n_results=10\n",
    "    )\n",
    "    \n",
    "    # Calculate precision for each query in batch\n",
    "    for query_idx, (ground_truth_id, ids) in enumerate(zip(batch_ground_truth_ids, results[\"ids\"])):\n",
    "        original_ids = [id.split(\"_\")[0] for id in ids]\n",
    "        precision = sum([1 for id in original_ids if id == ground_truth_id]) / len(original_ids)\n",
    "        precisions.append(precision)\n",
    "\n",
    "mean_precision = np.mean(precisions)\n",
    "mean_precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
